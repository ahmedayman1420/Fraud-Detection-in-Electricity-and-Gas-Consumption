{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB76NORGbQcF",
        "outputId": "39cb2a3d-8a02-4877-d691-06d516f7d341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Import Libraries ========== ----- ========== #\n",
        "!pip install pyspark\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from joblib import dump, load\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Import required libraries\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
        "from pyspark import SparkContext\n",
        "\n",
        "# Import necessary libraries\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv7oPjPTcJ0X",
        "outputId": "083a4a34-2edf-4bd0-fbab-d22a5e91ce00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "##The dataset is loaded to your GDrive so need to be mounted\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p5UFAIjcZ5N",
        "outputId": "36df3a77-80b5-4704-b101-3d81a71911a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row(client_catg='11', avg_elec_reading_remarque='6.971428571', avg_elec_consommation_level_1='352.4', avg_elec_consommation_level_2='10.57142857', avg_elec_consommation_level_3='0', avg_elec_consommation_level_4='0', avg_elec_months_number='4.628571429', avg_gaz_reading_remarque='0', avg_gaz_consommation_level_1='0', avg_gaz_consommation_level_2='0', avg_gaz_consommation_level_3='0', avg_gaz_consommation_level_4='0', avg_gaz_months_number='0', min_elec_reading_remarque='6', min_elec_consommation_level_1='38', min_elec_consommation_level_2='0', min_elec_consommation_level_3='0', min_elec_consommation_level_4='0', min_elec_months_number='2', min_gaz_reading_remarque='0', min_gaz_consommation_level_1='0', min_gaz_consommation_level_2='0', min_gaz_consommation_level_3='0', min_gaz_consommation_level_4='0', min_gaz_months_number='0', max_elec_reading_remarque='9', max_elec_consommation_level_1='1200', max_elec_consommation_level_2='186', max_elec_consommation_level_3='0', max_elec_consommation_level_4='0', max_elec_months_number='12', max_gaz_reading_remarque='0', max_gaz_consommation_level_1='0', max_gaz_consommation_level_2='0', max_gaz_consommation_level_3='0', max_gaz_consommation_level_4='0', max_gaz_months_number='0', std_elec_reading_remarque='1.24819197', std_elec_consommation_level_1='310.343472', std_elec_consommation_level_2='43.56893504', std_elec_consommation_level_3='0', std_elec_consommation_level_4='0', std_elec_months_number='2.101620023', std_gaz_reading_remarque='0', std_gaz_consommation_level_1='0', std_gaz_consommation_level_2='0', std_gaz_consommation_level_3='0', std_gaz_consommation_level_4='0', std_gaz_months_number='0', target='0')\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Import Dataset ========== ----- ========== #\n",
        "\n",
        "# Create a SparkContext object\n",
        "spark=SparkSession.builder\\\n",
        "    .master(\"local[5]\")\\\n",
        "    .appName(\"LogisticRegression\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load data into Spark DataFrame\n",
        "df = spark.read.format(\"csv\").option(\n",
        "    \"header\", \"true\").load(\"/content/drive/MyDrive/final_df.csv\")\n",
        "\n",
        "header = df.first()\n",
        "print(header)\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "I-DouWA4dFMw"
      },
      "outputs": [],
      "source": [
        "# ========== ----- ========== Prepare The Data ========== ----- ========== #\n",
        "\n",
        "# Perform some data preprocessing using the map function\n",
        "def preprocess(row):\n",
        "    # Convert string fields to numeric fields\n",
        "    row = [float(x) if x.isdigit() else x for x in row]\n",
        "    # Handle missing values\n",
        "    row = [0.0 if x is None else x for x in row]\n",
        "    return row\n",
        "\n",
        "\n",
        "df = df.rdd.map(preprocess).toDF(df.columns)\n",
        "\n",
        "df = df.withColumn(\"avg_elec_reading_remarque\", df[\"avg_elec_reading_remarque\"].cast(\"double\"))\\\n",
        "      .withColumn(\"avg_elec_consommation_level_1\", df[\"avg_elec_consommation_level_1\"].cast(\"double\"))\\\n",
        "      .withColumn(\"avg_elec_consommation_level_2\", df[\"avg_elec_consommation_level_2\"].cast(\"double\"))\\\n",
        "      .withColumn(\"avg_elec_months_number\", df[\"avg_elec_months_number\"].cast(\"double\"))\\\n",
        "      .withColumn(\"std_elec_reading_remarque\", df[\"std_elec_reading_remarque\"].cast(\"double\"))\\\n",
        "      .withColumn(\"std_elec_consommation_level_1\", df[\"std_elec_consommation_level_1\"].cast(\"double\"))\\\n",
        "      .withColumn(\"std_elec_consommation_level_2\", df[\"std_elec_consommation_level_2\"].cast(\"double\"))\\\n",
        "      .withColumn(\"std_elec_months_number\", df[\"std_elec_months_number\"].cast(\"double\"))\\\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYOyfAWidFpm",
        "outputId": "05d84fe5-c9ea-4f79-8e6b-2ab981450792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Area Under ROC Curve: 0.6866667937364653\n"
          ]
        }
      ],
      "source": [
        "# ========== ----- ========== Logistic Regression Model ========== ----- ========== #\n",
        "\n",
        "# Define input features and target variable\n",
        "input_cols = df.columns[:-1]\n",
        "assembler = VectorAssembler(inputCols=input_cols, outputCol='features',handleInvalid=\"skip\")\n",
        "data = assembler.transform(df).select(col(\"features\"), col(\"target\").alias(\"label\")).na.drop()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "(training_data, testing_data) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Build the logistic regression model\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
        "model = lr.fit(training_data)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "predictions = model.transform(testing_data)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print('Area Under ROC Curve:', evaluator.evaluate(predictions))\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eWcL-nLTdXHN"
      },
      "outputs": [],
      "source": [
        "# ========== ----- ========== Spark Session ========== ----- ========== #\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()\n",
        "\n",
        "# ========== ----- ========== End ========== ----- ========== #"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
